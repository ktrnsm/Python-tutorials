amacımız doğru model yapısını bulmak.
aşırı öğrenme ve eksik öğrenme sorunlarından kaçınmak.
optimal model yapısını çok fazla parametre etkiler.

radyo dinlediğinizi hyal edin eski tip frekansı değiştirierek kanal bulunan.
güzel bir kanal buldunuz ama biraz cızırtılı geliyor ses. bunu netleştirmek için ince ayar yapılıyor.
bu işleme model tuning deniyor ve makine öğrenmesi yapısında bu ince ayarın adı hiper parametredir.

örnek olarak bir regresyon yapısını düşünelim.
y=B0 + B1X1 + B2X2+....+BkXk
bu denklemdiki Beta değerlerini kusursuza yakın tahmin etmek için kullandığımız yapılara hiper parametre denir.
beta'ların daha doğru sonuç üretmesini istiyoruz.
Hiper parametre optimizasyonu içerisinde çok farklı yapılar bulundurur.
train ve test setlerini a-doğru biçimde ayırmak hiper parametre optimasyonudur. 
Parmetreler Beta'lar modelin sonucudur biz bunu belirlemiyoruz.
ancak hiper parametreleri biz ayarlarız ve buna model tunning denilir.

çapraz doğrulama sonucunu inceleyelim

mse be r2 değerlerinde mühim olan test verisi sonuçlarıdır.
eğitim verisi değerleri ile arasındaki farkı gözlemlemek için kullanıyoruz.

random state değerini ve %20 olarak verdiğimiz test train parçalamasını değiştirdiğimizde sonuçlarda oynamalar olduğunu gözlemliyoruz.

biz yine daha önce çalıştığımız data üzerinden gideceğiz.
Daha önceki örnekte olduğu gibi aynı şekilde ilerleyip train ve test olarak datayı bölüp devam ediyoruz.
şimdi modelimizin kalitesini görmek adına bu modeli test ve train olarak bir fonksiyona gönderiyoruz.

amacımız yüksek r2 değeri ve düşük mse değerine ulaşmak.

est_size=0.2,random_state=42 bu iki değer bizim modelimizdeki hiperparametrelerdir. bu değerleri değiştirdikçe sonuçlarımız değişecektir.

eğitim data setinin de kendi içerisinde parçalanarak iterasyona girmesi ve herbirisi için bir değer ortaya çıkartması.
bu parçalama işlemini KFold yapısı sağlayacaktır.
parçalama için iterasyon yapısını oluşturmamız gerekiyor.


